{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c05e459",
   "metadata": {},
   "source": [
    "Intent Classifier\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e388ead",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9d1a13",
   "metadata": {},
   "source": [
    "## 문장을 입력받아 intent를 분류하는 모델\n",
    "\n",
    "* Bert-base-multilingual-cased 모델을 3i4k 데이터 셋으로 Fine-tunning 하였습니다.\n",
    "* 코드는 huggingface의 Fine-tuning a pretrained model 문서를 참조하였습니다.\n",
    "* workspace는 Ainize의 workspace를 사용하였습니다.\n",
    "* Demo버전은 Ainize에서 확인 가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed7d86",
   "metadata": {},
   "source": [
    "##### 사전학습 모델 : [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "##### 데이터 셋 : [3i4k](https://huggingface.co/datasets/kor_3i4k)\n",
    "##### 코드 참조 : [huggingface](https://huggingface.co/transformers/training.html)\n",
    "##### workspace : [Ainize](https://ainize.ai/workspace)\n",
    "##### endpoint : [Ainize](https://main-kor-3i4k-bert-base-cased-rjdm1324.endpoint.ainize.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9882cc46",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리를 import 합니다.\n",
    "\n",
    "* Dataset : dataset을 trainer에 맞는 형식으로 만들기 위해 사용합니다.\n",
    "* TrainingArguments, Trainer : 모델 fine-tuning을 위해 사용합니다.\n",
    "* BertTokenizer, BertForSequenceClassification : huggingface에서 사전학습된 tokenizer와 model을 사용하기 위해 사용합니다.\n",
    "* LabelEncoder : label을 dataset에 맞는 형식으로 만들기 위해 사용합니다.\n",
    "* accuracy_score : 모델 정확도 측정을 위해 사용합니다.\n",
    "* cuda : GPU 사용을 위해 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb26d42f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.8.2 in /opt/conda/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.9.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (0.0.45)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (0.0.12)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (4.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (20.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (2021.7.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (0.10.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (4.60.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.8.2) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from huggingface-hub==0.0.12->transformers==4.8.2) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.8.2) (2.4.7)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.6.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.8.2) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.8.2) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.8.2) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.8.2) (1.26.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.8.2) (3.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.8.2) (8.0.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.8.2) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71bbb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import  TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch import cuda\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0828639",
   "metadata": {},
   "source": [
    "### GPU는 [AI NETWORK workspace]()에서 제공하는 GPU를 사용하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bd2572",
   "metadata": {},
   "source": [
    "* gpu를 사용하기 위해 device를 cuda로 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02232961",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efafc7b",
   "metadata": {},
   "source": [
    "### 학습에 필요한 파라미터를 설정하고 모델과 토크나이저 데이터 셋을 불러옵니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721ca72b",
   "metadata": {},
   "source": [
    "* 분류 case가 7개이기 때문에 num_labels는 7로 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e992e83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=7\n",
    "max_length = 256\n",
    "batch_size = 16\n",
    "num_epochs = 3\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1261be28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9916a101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizer_config.json',\n",
       " './special_tokens_map.json',\n",
       " './vocab.txt',\n",
       " './added_tokens.json',\n",
       " './tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=False)\n",
    "tokenizer.save_pretrained(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcaf72a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset kor_3i4k (/workspace/.cache/huggingface/datasets/kor_3i4k/default/1.1.0/5cd76dab10e6a5f36fd0ae9e1d01a725b6312307a5fd991a10b423e49e690dfe)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"kor_3i4k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37402be",
   "metadata": {},
   "source": [
    "### 데이터 셋을 train set과 test set으로 나누고 tokenizing을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37c886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list(dataset['train']['text'])\n",
    "y_train = list(dataset['train']['label'])\n",
    "X_val = list(dataset['test']['text'])\n",
    "y_val = list(dataset['test']['label'])\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation = True, max_length =max_length)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation = True, max_length =max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d48514",
   "metadata": {},
   "source": [
    "### tokenizing된 data를 data set으로 변환하는 class를 선언한 후 학습 시킬 data set으로 만들어 줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44a482c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c625da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96cc079",
   "metadata": {},
   "source": [
    "### accuracy를 계산할 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cfb2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1006d2a",
   "metadata": {},
   "source": [
    "### TrainerArgument를 설정한 후 trainer를  설정하고 학습을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10aca07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate =  learning_rate ,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_steps= log_interval ,\n",
    "    output_dir=\"output\",\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='log',\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfcacf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ada652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c62d021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 55134\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5169\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5169' max='5169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5169/5169 39:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.228200</td>\n",
       "      <td>0.657881</td>\n",
       "      <td>0.805424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.571649</td>\n",
       "      <td>0.834994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.551400</td>\n",
       "      <td>0.507469</td>\n",
       "      <td>0.849371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>0.468215</td>\n",
       "      <td>0.853619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.404701</td>\n",
       "      <td>0.866852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.446900</td>\n",
       "      <td>0.417196</td>\n",
       "      <td>0.870446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.435100</td>\n",
       "      <td>0.414374</td>\n",
       "      <td>0.870283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.377815</td>\n",
       "      <td>0.879431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.393021</td>\n",
       "      <td>0.876164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.366140</td>\n",
       "      <td>0.876981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.341900</td>\n",
       "      <td>0.359467</td>\n",
       "      <td>0.885476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.371155</td>\n",
       "      <td>0.884823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.304100</td>\n",
       "      <td>0.338505</td>\n",
       "      <td>0.889397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.297700</td>\n",
       "      <td>0.327590</td>\n",
       "      <td>0.892991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.290400</td>\n",
       "      <td>0.346538</td>\n",
       "      <td>0.893155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.281300</td>\n",
       "      <td>0.339175</td>\n",
       "      <td>0.894135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.292300</td>\n",
       "      <td>0.336428</td>\n",
       "      <td>0.888090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.212600</td>\n",
       "      <td>0.367444</td>\n",
       "      <td>0.891031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.199700</td>\n",
       "      <td>0.381211</td>\n",
       "      <td>0.893645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>0.368177</td>\n",
       "      <td>0.893318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.197900</td>\n",
       "      <td>0.360677</td>\n",
       "      <td>0.894135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>0.349507</td>\n",
       "      <td>0.896422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.341603</td>\n",
       "      <td>0.896259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.171300</td>\n",
       "      <td>0.358951</td>\n",
       "      <td>0.896912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.348050</td>\n",
       "      <td>0.894462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-200\n",
      "Configuration saved in output/checkpoint-200/config.json\n",
      "Model weights saved in output/checkpoint-200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-400\n",
      "Configuration saved in output/checkpoint-400/config.json\n",
      "Model weights saved in output/checkpoint-400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-600\n",
      "Configuration saved in output/checkpoint-600/config.json\n",
      "Model weights saved in output/checkpoint-600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-800\n",
      "Configuration saved in output/checkpoint-800/config.json\n",
      "Model weights saved in output/checkpoint-800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-1000\n",
      "Configuration saved in output/checkpoint-1000/config.json\n",
      "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-1200\n",
      "Configuration saved in output/checkpoint-1200/config.json\n",
      "Model weights saved in output/checkpoint-1200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-1400\n",
      "Configuration saved in output/checkpoint-1400/config.json\n",
      "Model weights saved in output/checkpoint-1400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-1600\n",
      "Configuration saved in output/checkpoint-1600/config.json\n",
      "Model weights saved in output/checkpoint-1600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-1800\n",
      "Configuration saved in output/checkpoint-1800/config.json\n",
      "Model weights saved in output/checkpoint-1800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-2000\n",
      "Configuration saved in output/checkpoint-2000/config.json\n",
      "Model weights saved in output/checkpoint-2000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-2200\n",
      "Configuration saved in output/checkpoint-2200/config.json\n",
      "Model weights saved in output/checkpoint-2200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-2400\n",
      "Configuration saved in output/checkpoint-2400/config.json\n",
      "Model weights saved in output/checkpoint-2400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-2600\n",
      "Configuration saved in output/checkpoint-2600/config.json\n",
      "Model weights saved in output/checkpoint-2600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-2800\n",
      "Configuration saved in output/checkpoint-2800/config.json\n",
      "Model weights saved in output/checkpoint-2800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-3000\n",
      "Configuration saved in output/checkpoint-3000/config.json\n",
      "Model weights saved in output/checkpoint-3000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-3200\n",
      "Configuration saved in output/checkpoint-3200/config.json\n",
      "Model weights saved in output/checkpoint-3200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-3400\n",
      "Configuration saved in output/checkpoint-3400/config.json\n",
      "Model weights saved in output/checkpoint-3400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-3600\n",
      "Configuration saved in output/checkpoint-3600/config.json\n",
      "Model weights saved in output/checkpoint-3600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-3800\n",
      "Configuration saved in output/checkpoint-3800/config.json\n",
      "Model weights saved in output/checkpoint-3800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-4200\n",
      "Configuration saved in output/checkpoint-4200/config.json\n",
      "Model weights saved in output/checkpoint-4200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-4400\n",
      "Configuration saved in output/checkpoint-4400/config.json\n",
      "Model weights saved in output/checkpoint-4400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-4600\n",
      "Configuration saved in output/checkpoint-4600/config.json\n",
      "Model weights saved in output/checkpoint-4600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-4800\n",
      "Configuration saved in output/checkpoint-4800/config.json\n",
      "Model weights saved in output/checkpoint-4800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to output/checkpoint-5000\n",
      "Configuration saved in output/checkpoint-5000/config.json\n",
      "Model weights saved in output/checkpoint-5000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-2800 (score: 0.3275899887084961).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5169, training_loss=0.356829648599977, metrics={'train_runtime': 2376.638, 'train_samples_per_second': 69.595, 'train_steps_per_second': 2.175, 'total_flos': 1.4650266110839308e+16, 'train_loss': 0.356829648599977, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b2754",
   "metadata": {},
   "source": [
    "fragment (0), statement (1), question (2), command (3), rhetorical question (4), rhetorical command (5) and intonation-depedent utterance (6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6329fa67",
   "metadata": {},
   "source": [
    "### 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df96992a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 6121\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='192' max='192' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [192/192 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3275899887084961,\n",
       " 'eval_accuracy': 0.892991341284104,\n",
       " 'eval_runtime': 23.8916,\n",
       " 'eval_samples_per_second': 256.198,\n",
       " 'eval_steps_per_second': 8.036,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4853e",
   "metadata": {},
   "source": [
    "### 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c3105d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in kor_3i4k_bert_base_cased/config.json\n",
      "Model weights saved in kor_3i4k_bert_base_cased/pytorch_model.bin\n",
      "tokenizer config file saved in kor_3i4k_bert_base_cased/tokenizer_config.json\n",
      "Special tokens file saved in kor_3i4k_bert_base_cased/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('kor_3i4k_bert_base_cased/tokenizer_config.json',\n",
       " 'kor_3i4k_bert_base_cased/special_tokens_map.json',\n",
       " 'kor_3i4k_bert_base_cased/vocab.txt',\n",
       " 'kor_3i4k_bert_base_cased/added_tokens.json',\n",
       " 'kor_3i4k_bert_base_cased/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"kor_3i4k_bert_base_cased\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd7171d",
   "metadata": {},
   "source": [
    "# Test Prediction\n",
    "* 출력을 얻기위한 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a2dc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_length, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    prediction = probs.argmax().item()\n",
    "    intent=\"\"\n",
    "    if prediction==0 :\n",
    "        intent=\"Fragment\"\n",
    "    elif prediction==1 :\n",
    "        intent=\"statement\"\n",
    "    elif prediction==2 :\n",
    "        intent=\"question\"\n",
    "    elif prediction==3 :\n",
    "        intent=\"command\"\n",
    "    elif prediction==4 :\n",
    "        intent=\"rhetorical question\"\n",
    "    elif prediction==5 :\n",
    "        intent=\"rhetorical command\"\n",
    "    elif prediction==6 :\n",
    "        intent=\"intonation-depedent utterance\"\n",
    "    return intent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c112d3a6",
   "metadata": {},
   "source": [
    "### text를 입력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"\"\"\n",
    "    너 이것좀 해라.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18764365",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = get_prediction(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847f317",
   "metadata": {},
   "source": [
    "### text의 intent를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4ebdc242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "command\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac4882",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
